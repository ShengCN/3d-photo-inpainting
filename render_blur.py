import pickle
import os
import numpy as np
from tqdm import tqdm
import os
import sys

sys.path.insert(0, '/home/sheng30/Documents/Research/Bokeh/app/DScatter')
from scatter import Multi_Layer_Renderer

from torchvision import utils
import torch
import cv2


def render_LDI(LDI_file, params: dict):
    """
    Render lens blur results given parameters
    @param LDI_file: file path to a binary LDI generated by 3d-photo
    @param params: camera parameters
    @return: dict{'LDI': bokeh rendered by LDI, 'single': bokeh rendered by single layer}
    """
    if not os.path.exists(LDI_file):
        raise ValueError("Not find file:", LDI_file)
    assert ('focal' in params) and \
           ('lens_effect' in params) and \
           ('img_size' in params) and \
           ('lens_size' in params), \
        "<focal>,<lens_effect>,<img_size>,<lens_size> should be in params"

    eps = 1e-6
    focal = params['focal']
    img_size = params['img_size']
    lens_size = params['lens_size']
    lens_effect = params['lens_effect']

    LDI = compute_LDI(LDI_file)
    resized_LDI = resize_LDI(LDI, img_size)
    sorted_LDI = sort_LDI(resized_LDI)

    LDI_rgba = sorted_LDI[..., :4]
    LDI_depth = sorted_LDI[..., 4:]
    LDI_disp = LDI_rgba[..., -1:] * (1.0 / (LDI_depth + eps))

    # out-painting the disp layers
    for i in range(len(LDI_rgba)):
        LDI_disp[i] = outpainting_disp(LDI_disp[i], LDI_rgba[i, ..., -1:])

    renderer = Multi_Layer_Renderer(lens_size).cuda()
    lens_effect = (torch.ones(1, 1) * lens_effect).cuda().float()

    # render single layer
    single_layer_rgba = resized_LDI[0, ..., :4]
    single_layer_disp = single_layer_rgba[..., -1:] * (1.0 / (resized_LDI[0, ..., -1:] + eps))
    single_layer_tensor = torch.tensor(np.concatenate([single_layer_rgba, single_layer_disp], axis=-1)[None, ...].transpose((0, 3, 1, 2)))[None, ...].cuda().float()

    single_layer_bokeh = renderer.forward(single_layer_tensor, lens_effect, focal)

    # render LDI
    multi_layer_tensor = torch.tensor(np.concatenate([LDI_rgba, LDI_disp], axis=-1).transpose((0,3,1,2)))[:, None, ...].cuda().float()
    multi_layer_bokeh = renderer.forward(multi_layer_tensor, lens_effect, focal)

    return {
        'single_layer': single_layer_bokeh,
        'multi_layer' : multi_layer_bokeh
    }


def sort_LDI(LDI: np.array):
    """
    Sort the LDI to our representation.
    @param LDI: LDI in numpy array format, N x H x W x 5
    @return: The new sorted numpy array
    """
    max_layers, h, w = LDI.shape[:3]
    sorted_LDI_rgba = np.array([np.zeros((h, w, 4)) for i in range(max_layers)])
    sorted_LDI_disp = np.array([np.zeros((h, w, 1)) for i in range(max_layers)])

    LDI_rgba = np.array(LDI[:, ..., :4])
    LDI_disp = np.abs(LDI[:, ..., 4:])

    for hi in tqdm(range(h), desc='sort LDI'):
        for wi in range(w):
            sorted_ind = np.argsort(LDI_disp[:, hi, wi, 0])

            for li in range(max_layers):
                sorted_LDI_rgba[li, hi, wi, :] = LDI_rgba[sorted_ind[li], hi, wi, :]
                sorted_LDI_disp[li, hi, wi, :] = LDI_disp[sorted_ind[li], hi, wi, :]

    ret = np.concatenate([sorted_LDI_rgba, sorted_LDI_disp], axis=3)
    return ret


def resize_LDI(LDI, newsize: int):
    """
    Resize the RGBAD to specific new size
    @param LDI: LDI In np array
    @return: Resized LDI in np array
    """

    def max_resize(img, newsize):
        h, w, c = img.shape[:3]
        if h > w:
            nh = newsize
            nw = int(w / h * nh)
        else:
            nw = newsize
            nh = int(h / w * nw)

        ret_img = np.zeros((nh, nw, c))
        for i in range(c):
            ret_img[..., i] = cv2.resize(img[..., i], (nw, nh))
        return ret_img

    ret = np.array([max_resize(LDI[i], newsize) for i in range(len(LDI))])
    return ret


def compute_LDI(LDI_file: str):
    """
    Compute the LDI given the binary LDI file
    @param LDI_file: path to the LDI file
    @return: LDI in np format
    """
    h, w = 0, 0
    max_layers = 5

    with open(LDI_file, 'rb') as f:
        info_on_pix = pickle.load(f)

    # image size
    for pix in tqdm(list(info_on_pix.keys())):
        hi, wi = pix
        h = max(hi, h)
        w = max(wi, w)

    h += 1
    w += 1
    LDI_rgba = np.array([np.zeros((h, w, 4)) for i in range(max_layers)])
    LDI_depth = np.array([np.zeros((h, w, 1)) for i in range(max_layers)])

    for pix_xy, pix_list in tqdm(info_on_pix.items()):
        for pix_idx, pix_info in enumerate(pix_list):
            rgb = pix_info['color']
            disp = pix_info['depth']
            i, j = pix_xy

            LDI_rgba[pix_idx][i, j, :3] = rgb / 255.0
            LDI_rgba[pix_idx][i, j, 3:] = 1.0
            LDI_depth[pix_idx][i, j] = disp

    LDI = np.concatenate([LDI_rgba, LDI_depth], axis=3)
    return LDI


def outpainting_disp(disp, mask):
    oh, ow = disp.shape[:2]
    black_size = max(ow, oh)

    # Filling the hmap by dilation
    kernel = np.ones((black_size, black_size), np.uint8)
    uintmask = (mask * 255.0).astype(np.uint8)
    dilated_mask = cv2.dilate(uintmask, kernel, 1)

    if len(dilated_mask.shape) != len(uintmask.shape):
        dilated_mask = dilated_mask[..., np.newaxis]

    inpainting_mask = dilated_mask - uintmask

    min_disp = disp.min()
    max_disp = disp.max()

    normalized_disp = (disp - min_disp) / (max_disp - min_disp)
    inpainted_disp = \
        cv2.inpaint((normalized_disp * 65536.0).astype(np.uint16), inpainting_mask[..., 0], 3, cv2.INPAINT_TELEA)[
            ..., None]
    inpainted_disp = inpainted_disp / 65536.0
    inpainted_disp = inpainted_disp * (max_disp - min_disp) + min_disp

    return inpainted_disp


if __name__ == '__main__':
    params = {
        'focal'      : 0,
        'img_size'   : 256,
        'lens_size'  : 21,
        'lens_effect': 2.0
    }

    bokeh = render_LDI('./test.bin', params)
